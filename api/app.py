# api/app.py

from __future__ import annotations

import os
from io import BytesIO
from uuid import uuid4

import pandas as pd
from fastapi import FastAPI, UploadFile, File, Form, HTTPException
from fastapi.responses import JSONResponse, FileResponse

from agent.tools import (
    basic_eda,
    detect_task,
    train_baseline,
    build_report,
    make_plots_base64,
    analyze_dataset,       # üëà –¥–æ–±–∞–≤–∏–ª–∏
    build_recommendations, # üëà —É–∂–µ –±—ã–ª–æ
)

app = FastAPI(
    title="Nikita DS Agent",
    description="–ó–∞–≥—Ä—É–∑–∏ CSV ‚Üí –ø–æ–ª—É—á–∏ EDA –∏ –±–∞–∑–æ–≤—É—é –º–æ–¥–µ–ª—å",
    version="0.1.0",
)

# –ø—Ä–æ—Å—Ç–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –≤ –ø–∞–º—è—Ç–∏
RUNS: dict[str, dict] = {}


# ---------- –≤—Å–ø–æ–º–æ–≥–∞–ª–∫–∏ ----------

def read_csv_safely(file_bytes: bytes) -> pd.DataFrame:
    bio = BytesIO(file_bytes)

    variants = [
        {},
        {"sep": ";"},
        {"encoding": "utf-8-sig"},
        {"encoding": "cp1251"},
        {"sep": ";", "encoding": "cp1251"},
        {"encoding": "latin-1"},
        {"sep": ";", "encoding": "latin-1"},
    ]

    for kwargs in variants:
        try:
            bio.seek(0)
            df = pd.read_csv(bio, on_bad_lines="skip", **kwargs)
            if df.shape[1] > 0:
                return df
        except Exception:
            continue

    raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å CSV –Ω–∏ —Å –æ–¥–Ω–æ–π –∫–æ–º–±–∏–Ω–∞—Ü–∏–µ–π –∫–æ–¥–∏—Ä–æ–≤–∫–∞/—Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å")


def normalize_columns(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df.columns = [
        col.strip()
        .replace(" ", "_")
        .replace(".", "_")
        .replace("-", "_")
        .replace("/", "_")
        for col in df.columns
    ]
    return df


# ---------- UI ----------

@app.get("/ui")
def ui():
    return FileResponse(os.path.join("api", "static", "frontend.html"))


# ---------- API ----------

@app.get("/")
def root():
    return {"msg": "Nikita DS Agent is running"}


@app.post("/upload")
async def upload_dataset(
    file: UploadFile = File(...),
    target: str | None = Form(default=None),
):
    try:
        contents = await file.read()

        # 1) —á–∏—Ç–∞–µ–º –∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º
        df = read_csv_safely(contents)
        df = normalize_columns(df)

        # 2) –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º target, –µ—Å–ª–∏ –ø—Ä–∏—Å–ª–∞–ª–∏
        if target is not None:
            target = (
                target.strip()
                .replace(" ", "_")
                .replace(".", "_")
                .replace("-", "_")
                .replace("/", "_")
            )

        # 3) EDA
        eda = basic_eda(df)

        # 4) –æ–ø—Ä–µ–¥–µ–ª—è–µ–º –∑–∞–¥–∞—á—É
        task = detect_task(df, target=target)

        # 5) –∞–Ω–∞–ª–∏–∑ –ø—Ä–æ–±–ª–µ–º –¥–∞—Ç–∞—Å–µ—Ç–∞ (–∫–æ–Ω—Å—Ç–∞–Ω—Ç—ã, –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏, –¥–∏—Å–±–∞–ª–∞–Ω—Å –∏ —Ç.–ø.)
        problems = analyze_dataset(df, eda, task)

        # 6) –ø—Ä–æ–±—É–µ–º –æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å
        model_res = None
        if task["task"] != "eda" and task["target"]:
            model_res = train_baseline(
                df,
                task["target"],
                task["task"],
            )

        # 7) –æ—Ç—á—ë—Ç –∏ –≥—Ä–∞—Ñ–∏–∫–∏
        report_text = build_report(df, eda, task, model_res)
        plots = make_plots_base64(df)

        # 8) —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ ‚Äî —Ç–µ–ø–µ—Ä—å —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π —Å–∏–≥–Ω–∞—Ç—É—Ä–æ–π
        recs = build_recommendations(
            df=df,
            eda=eda,
            task=task,
            problems=problems,
            model=model_res,
        )

        # 9) —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∑–∞–ø—É—Å–∫
        run_id = f"run_{uuid4().hex[:8]}"
        RUNS[run_id] = {
            "filename": file.filename,
            "eda": eda,
            "task": task,
            "problems": problems,
            "model": model_res,
            "report": report_text,
            "plots": plots,
            "recommendations": recs,
            "columns": list(df.columns),
        }

        return JSONResponse(
            {
                "run_id": run_id,
                "filename": file.filename,
                "eda": eda,
                "task": task,
                "problems": problems,
                "model": model_res,
                "report": report_text,
                "plots": plots,
                "recommendations": recs,
            }
        )

    except ValueError as e:
        raise HTTPException(
            status_code=400,
            detail={
                "error": "failed_to_process_file",
                "details": str(e),
                "hint": "–ø—Ä–æ–≤–µ—Ä—å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å (',' –∏–ª–∏ ';'), –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫ –∏ target",
            },
        )
    except Exception as e:
        raise HTTPException(
            status_code=400,
            detail={
                "error": "failed_to_process_file",
                "details": str(e),
                "hint": "–ø—Ä–æ–≤–µ—Ä—å CSV –∏ target",
            },
        )


@app.get("/runs/{run_id}")
def get_run(run_id: str):
    if run_id not in RUNS:
        raise HTTPException(status_code=404, detail="run_id not found")
    return RUNS[run_id]


@app.get("/runs")
def list_runs():
    items = []
    for run_id, data in RUNS.items():
        items.append({
            "run_id": run_id,
            "filename": data.get("filename"),
            "task": data.get("task"),
            "has_model": data.get("model") is not None,
        })
    return items
